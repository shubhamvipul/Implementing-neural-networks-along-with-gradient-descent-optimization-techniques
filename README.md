# Implementing Neural-networks from scratch

Testing gradient descent optimization techniques like GD with momentum, acceleration, RMSProp, ADAM.
